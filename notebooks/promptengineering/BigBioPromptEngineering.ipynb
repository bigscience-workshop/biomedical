{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt engineering with BigBio\n",
    "#### Last Updated: 2022.07.05\n",
    "\n",
    "The following tutorial will show you how to:\n",
    "\n",
    "(1) Generate prompts using the specific `BigBio` fork of *PromptSource*. <br>\n",
    "(2) Generate a new prompt task in `LmEval` <br>\n",
    "(3) Evaluate a model of choice for your dataset!\n",
    "\n",
    "We will be using the dataset `chemprot` within BigBio. We also provide instructions to create prompts **for your own bigbio dataset**.\n",
    "\n",
    "**NOTE** This tutorial uses 3 packages: `promptsource`, `lm-eval-harness` and `bigbio`. All of these need to be installed (instructions will be provided) but will require some work outside of the notebook in order to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Preliminaries\n",
    "\n",
    "In order to work with these packages, you will need to have\n",
    "\n",
    "- A GitHub account and familiarity with CLI access\n",
    "- Environment management\n",
    "- Python 3.3+\n",
    "\n",
    "We highly recommend you create an environment in order to not create any dependency issues. You can do this as follows:\n",
    "\n",
    "#### Create a conda environment\n",
    "The following instructions will create an Anaconda bigscience-biomedical environment.\n",
    "\n",
    "Install anaconda for your appropriate operating system.\n",
    "Run the following command while in the biomedical folder (you can pick your python version):\n",
    "\n",
    "```\n",
    "conda create -n bigbioprompting python=3.9 # Creates a conda env\n",
    "conda activate bigbioprompting  # Activate your conda environment\n",
    "```\n",
    "\n",
    "#### Create a venv environment\n",
    "\n",
    "Python 3.3+ has venv automatically installed; official information is found here.\n",
    "\n",
    "```\n",
    "python3 -m venv bigbioprompting\n",
    "source bigbioprompting/bin/activate  # activate environment\n",
    "```\n",
    "\n",
    "With your environment of choice active, please continue.\n",
    "\n",
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conda env remove -n bigbioprompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install BigBio\n",
    "\n",
    "The following exercise will work with existing datasets in `BigBio`.\n",
    "\n",
    "#### Creating prompts for datasets in `BigBio`\n",
    "\n",
    "Install the `BigBio` repository in your chosen environment.\n",
    "\n",
    "```\n",
    "pip install git+https://github.com/bigscience-workshop/biomedical.git\n",
    "```\n",
    "\n",
    "#### Creating prompts for your own dataset\n",
    "\n",
    "If you want to develop with your own datasets, you should **fork** the `BigBio` repo. Once you fork the repo, clone the contents and install directly.\n",
    "\n",
    "```\n",
    "git clone git@github.com:<your_fork>/biomedical.git\n",
    "cd biomedical\n",
    "pip install -e .\n",
    "cd ../\n",
    "```\n",
    "\n",
    "The contents of the tutorial will not dive into how to create a dataloader (this information can be found [here](https://github.com/bigscience-workshop/biomedical/blob/master/CONTRIBUTING.md)). Provided you create a dataloader, you can make prompts ***on either the source of BigBio views***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Install lm-evaluation-harness\n",
    "\n",
    "In order to integrate your templates and evaluate your prompt, we will work with `lm-evaluation-harness`. First, we download the package as follows:\n",
    "\n",
    "```\n",
    "git clone --branch bigbio --single-branch git@github.com:bigscience-workshop/lm-evaluation-harness.git\n",
    "cd lm-evaluation-harness\n",
    "pip install -e .\n",
    "cd ..\n",
    "```\n",
    "\n",
    "**NOTE** This step can be done later, however it may override the `promptsource` installation below. You may need to uninstall and ensure you follow instructions from Step 3 onwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Install BigBio promptsource and run the GUI\n",
    "\n",
    "In collaboration with the PromptSource team, we created a fork of the original repo to support `BigBio` tasks specifically. You can clone and install this fork as such:\n",
    "\n",
    "```\n",
    "git clone https://github.com/OpenBioLink/promptsource\n",
    "cd promptsource\n",
    "pip install -e .\n",
    "cd ../\n",
    "```\n",
    "\n",
    "This will install **PromptSource**, which allows you to create prompts. **Please note, there may be an issue deploying the GUI editor for promptsource with a newer version of protobuf, so please ensure your version is <3.20.X**.\n",
    "\n",
    "You can check your protobuf version with `pip freeze | grep protobuf`. If it is higher than 3.20.X, you can run a command as such:\n",
    "\n",
    "```\n",
    "pip uninstall -y protobuf\n",
    "pip install protobuf==3.19.4\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create an authentication file in order to use the GUI app. In the root directory of promptsource, make a file called `cred.cfg` with only the following contents:\n",
    "\n",
    "```\n",
    "[authentication]\n",
    "username=bigscience\n",
    "password=bigscience\n",
    "```\n",
    "\n",
    "Your directory structure within promptsource should look as such:\n",
    "\n",
    "![Directory Structure](prompt_structure1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have installed `promptsource`, move to the root directory (i.e. `cd promptsource`) and run the following command:\n",
    "\n",
    "```\n",
    "streamlit run promptsource/app.py\n",
    "```\n",
    "\n",
    "You will first be prompted to log with this screen <br>\n",
    "\n",
    "![GuiLogin](guilogin.png)\n",
    "\n",
    "\n",
    "Log in with both username and password that matches your `cred.cfg`. You will then arrive at the GUI interface.\n",
    "\n",
    "![GuiLogin](guiprompt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the GUI to create prompts for custom datasets\n",
    "\n",
    "The list of datasets from the drop-down menu matches that of **your environment's `BigBio` installation** (see [here](https://github.com/OpenBioLink/promptsource/blob/815426a103087074c5c6f264147dae421194a822/promptsource/utils.py#L145) for the list of datasets from the drop-down menu.). For custom datasets, we *strongly* recommend following the developer instructions above using your fork of `BigBio`, and installing that from source.\n",
    "\n",
    "The GUI display will provide a link to the original dataset source code. By default, it points to the main branch of `BigBio`. For custom datasets, you can point to your personal fork by editing line 386 in `promptsource/promptsource/app.py` to match where your source code lives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Make your own prompt!\n",
    "\n",
    "To create a prompt, use the tab on the left-hand-side of the app.\n",
    "\n",
    "In \"Choose a mode\" choose **Sourcing**\n",
    "\n",
    "![source](source.png)\n",
    "\n",
    "\n",
    "Choose a dataset (ex: `chemprot`) and a subset corresponding to a bigbio view (ex: `chemprot_bigbio_kb`).\n",
    "\n",
    "![dset](datasetsubset.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main body of the prompt creator will show pre-existing prompts, or allow you to create new ones. **Creating prompts will require you to have some understanding of the dataset**. \n",
    "\n",
    "For this example, we are going to use the **Chemprot** dataset, and identify \n",
    "In the official chemprot dataset, the \"gold-standard\" labels are \"Regulator, upregulator, downregulator, agonist, antagonist\". For sake of the example, we will create a prompt that asks whether a given chemical has a **Modulator** relationship with a gene/protein target.\n",
    "\n",
    "First, come up with a **unique** name for your prompt. We will call this `is_modulator`.\n",
    "\n",
    "![ismodulator](ismodulator.png)\n",
    "\n",
    "\n",
    "After you click \"create\", you will receive an empty template as follows:\n",
    "\n",
    "![emptytemplate](emptytemplate.png)\n",
    "\n",
    "For this task, we are creating a natural language generation-based task. Our metric is \"Other\", as we do not have choices in text. Write your template as follows. <br>\n",
    "\n",
    "```\n",
    "{{ passages[0]['text'][0] }}\n",
    "\n",
    "What chemicals are modulators to their protein or gene targets from the above passage? Separate each chemical and gene or protein target pair with a comma. If there are none, say \"None.\"\n",
    "\n",
    "|||\n",
    "{% set ns = namespace(nonzero = false) %}{% for relation in relations %}{% if relation['type'] == \"Modulator\" %}{% set ns.nonzero = true %}{% endif %}{% endfor %}{% if ns.nonzero %}{% for relation in relations %}{% if relation['type'] == \"Modulator\" %}{% for entity in entities %}{% if entity['id'] == relation['arg1_id'] %}{{ entity['text'][0] }}{% endif %}{% endfor %}, {% for entity in entities %}{% if entity['id'] == relation['arg2_id'] %}{{ entity['text'][0] }}{% endif %}{% endfor %}\n",
    "{% endif %}{% endfor %}{% else %}None.{% endif %}\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "You can use the \"Select Example\" menu on the left to toggle through examples (example 27 in train in the `chemprot` dataset has a Modulator relation to check). You can observe whether your prompt operates as expected using the input example on the right hand side:\n",
    "\n",
    "![chemprotexample](chemprotexample.png)\n",
    "\n",
    "If you want more details on how to write prompts, you can follow Jinja templating tips [here](https://github.com/OpenBioLink/promptsource/blob/main/CONTRIBUTING.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Check your dataset template\n",
    "\n",
    "You should be able to find your updated template in `promptsource/promptsource/templates/your_dataset_name/your_dataset_view`.\n",
    "\n",
    "For chemprot, you should find it here:\n",
    "\n",
    "```\n",
    "promptsource/promptsource/templates/chemprot/chemprot_bigbio_kb/templates.yaml\n",
    "```\n",
    "\n",
    "![exampleprompttemplate](exampleprompttemplate.png)\n",
    "\n",
    "All templated prompts will appear in this one file.\n",
    "\n",
    "With that, you've generated your own template for prompting! Now we will evaluate it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Create an Evaluation Task for your dataset\n",
    "\n",
    "\n",
    "#### Create the task\n",
    "\n",
    "Now, we want to create a new task to evaluate our models. Place a file `yourdataset.py` in `lm-evaluation-harness/lm_eval/tasks` that fills out the criteria below:\n",
    "\n",
    "```python\n",
    "from lm_eval.base import BioTask\n",
    "\n",
    "_CITATION = \"\"\"\n",
    "PLACE_YOUR_CITATION_FOR_YOUR_DATASET_HERE\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class YourDatasetBase(BioTask):\n",
    "    VERSION = 0\n",
    "    DATASET_PATH = \"path/to/dataloader/script/from/bigbio\"\n",
    "    DATASET_NAME = None\n",
    "    SPLIT = None\n",
    "    \n",
    "    # Fill these out as T/F depending on your dataset\n",
    "    def has_training_docs(self):\n",
    "        return True\n",
    "\n",
    "    def has_validation_docs(self):\n",
    "        return True\n",
    "\n",
    "    def has_test_docs(self):\n",
    "        return True\n",
    "\n",
    "    def training_docs(self):\n",
    "        if self.has_training_docs():\n",
    "            return self.dataset[\"train\"]\n",
    "\n",
    "    def validation_docs(self):\n",
    "        if self.has_validation_docs():\n",
    "            return self.dataset[\"validation\"]\n",
    "\n",
    "    def test_docs(self):\n",
    "        if self.has_test_docs():\n",
    "            return self.dataset[\"test\"]  # you can replace with `train` to hack around\n",
    "\n",
    "\n",
    "class YourDatasetSplit(YourDatasetBase):\n",
    "    DATASET_NAME = \"yourdataset_bigbio_<schema>\"\n",
    "```\n",
    "\n",
    "A chemprot specific file is provided here:\n",
    "\n",
    "```python\n",
    "from lm_eval.base import BioTask\n",
    "\n",
    "_CITATION = \"\"\"\"\"\"\n",
    "\n",
    "class ChemprotBase(BioTask):\n",
    "    VERSION = 0\n",
    "    DATASET_PATH = \"/home/natasha/anaconda3/envs/bbp/lib/python3.9/site-packages/bigbio/biodatasets/chemprot\"\n",
    "    DATASET_NAME = \"Chemprot\"\n",
    "    SPLIT = None\n",
    "\n",
    "    def has_training_docs(self):\n",
    "        return True\n",
    "\n",
    "    def has_validation_docs(self):\n",
    "        return True\n",
    "\n",
    "    def has_test_docs(self):\n",
    "        return True\n",
    "\n",
    "    def training_docs(self):\n",
    "        if self.has_training_docs():\n",
    "            return self.dataset[\"train\"]\n",
    "\n",
    "    def validation_docs(self):\n",
    "        if self.has_validation_docs():\n",
    "            return self.dataset[\"validation\"]\n",
    "\n",
    "    def test_docs(self):\n",
    "        if self.has_test_docs():\n",
    "            return self.dataset[\"test\"]\n",
    "          \n",
    "class ChemprotKB(ChemprotBase):\n",
    "    DATASET_NAME = \"chemprot_bigbio_kb\"\n",
    "\n",
    "```\n",
    "\n",
    "**NOTE** In order to retrieve results, you **MUST** have a validation and testing set. \n",
    "\n",
    "If you do not know where your `BigBio` dataloading script is and you used an Anaconda environment, it is likely somewhere here:\n",
    "\n",
    "`/home/natasha/anaconda3/envs/<your_env_name>/lib/python3.9/site-packages/bigbio/biodatasets`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Update the `__init__` file to recognize your task\n",
    "\n",
    "Add this dataset task to `lm-evaluation-harness/lm_eval/tasks/__init__.py` by adding the following lines:\n",
    "\n",
    "```python\n",
    "from . import <your_dataset>  # Place this in the beginning import\n",
    "\n",
    "# Within TASK_REGISTRY, add the following command\n",
    "TASK_REGISTRY = {\n",
    "    ...\n",
    "    \"your_dataset_name\": yourdataset.Class_Corresponding_To_Schema\n",
    "}\n",
    "```\n",
    "\n",
    "(For example, Chemprot would look as such:)\n",
    "```python\n",
    "\n",
    "from . import chemprot\n",
    "\n",
    "TASK_REGISTRY = {\n",
    "    ...\n",
    "    \"chemprot\": chemprot.ChemprotKB,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Run your task\n",
    "\n",
    "Use the `main.py` script in `lm-evaluation-harness` as such:\n",
    "\n",
    "```\n",
    "python main.py --model hf-seq2seq --model_args pretrained=t5-small --tasks chemprot --device cuda\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbprompt",
   "language": "python",
   "name": "bbprompt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
